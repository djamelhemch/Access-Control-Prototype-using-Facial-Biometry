{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](logos/cesi_exia.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### **Project: Access Control Prototype using Facial Biometry**\n",
    "#### **Internship Period: 08/12/2021 - 03/02/2022**\n",
    "\n",
    "\n",
    "|Authors|Country|City|School|Campus|Position|Created|Updated|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|MJ. HEMCH|Algeria|Oran|CESI ALGERIE|Oran|Student|21/12/2021|21/12/2021|\n",
    "|NK. BENAMARA|Algeria|Oran|CESI ALGERIE|Oran|Internship Supervisor|21/12/2021|21/12/2021|\n",
    "\n",
    "---\n",
    "\n",
    "|Packages|Version|\n",
    "|---|---|\n",
    "|Numpy|1.19.5|\n",
    "|Opencv|4.5.4.60|\n",
    "|Tensorflow-GPU|1.15|\n",
    "|Keras|2.2.4|\n",
    "|VGG-Face Keras|0.6|\n",
    "|h5py|2.10.0|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nkben\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#load pretrained models\n",
    "\n",
    "vgg16_features = VGGFace(model='vgg16', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "resnet50_features = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=load_img('image.jpg',target_size=(224,224)) #load an image and resize to 224,224 like vgg face input size\n",
    "img=img_to_array(img) #convert the image to an array\n",
    "img=np.expand_dims(img,axis=0) #add the 4th dimension as a tensor to inject it inside the vgg face network\n",
    "img=utils.preprocess_input(img, version=1)\n",
    "img_encode=resnet50_features.predict(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2665097fc4ce516606e956c6204c3983ee82c67aa1a9762c0115b5dd20c4b36b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
