{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](logos/cesi_exia.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### **Internship Project: Access Control Prototype using Facial Biometry**\n",
    "#### **Internship Period: 08/12/2021 - 03/02/2022**\n",
    "\n",
    "\n",
    "|Authors|Country|City|School|Campus|Position|Created|Updated|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|MD. HEMCH|Algeria|Oran|CESI ALGERIE|Oran|Student|21/12/2021|21/12/2021|\n",
    "|NK. BENAMARA|Algeria|Oran|CESI ALGERIE|Oran|Internship Supervisor|21/12/2021|21/12/2021|\n",
    "\n",
    "---\n",
    "\n",
    "|Packages|Version|\n",
    "|---|---|\n",
    "|Numpy|1.19.5|\n",
    "|Opencv|4.5.4.60|\n",
    "|Tensorflow-GPU|1.15|\n",
    "|Keras|2.2.4|\n",
    "|VGG-Face Keras|0.6|\n",
    "|h5py|2.10.0|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH=os.getcwd()\n",
    "GALLERY_PATH=MAIN_PATH+'/gallery'\n",
    "DATASET_PATH=MAIN_PATH+'/dataset_cropped'\n",
    "MODELS=['vgg16', 'resnet50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vggface_model(model_type):\n",
    "    '''\n",
    "    this function load a pretrained VGG Face model (VGG16 or RESNET50)\n",
    "    '''\n",
    "    return VGGFace(model=model_type, include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "def extract_n_save(model_type, dataset_path, output_path):\n",
    "    ''''\n",
    "    this function extracts and saves features in a npy file\n",
    "    '''\n",
    "    print('----------------------------------------------------')\n",
    "    print('The Feature Extraction Work Has Started Using The {} Prerained Mode'.format(model_type.upper()))\n",
    "    print('----------------------------------------------------')\n",
    "    if model_type=='vgg16':\n",
    "        preprocess_vgg_version=1\n",
    "    elif model_type=='resnet50':\n",
    "        preprocess_vgg_version=2\n",
    "\n",
    "    vgg_face_model=load_vggface_model(model_type)\n",
    "    feature_vectors=[]\n",
    "    labels=[]\n",
    "    directories=os.listdir(dataset_path)\n",
    "    \n",
    "    for directory in directories:\n",
    "        print('Extracting features from {}'.format(str(directory)))\n",
    "        os.chdir(dataset_path+'/'+directory)\n",
    "        images=glob('*')\n",
    "        for image in tqdm(images):\n",
    "            img=load_img(image,target_size=(224,224)) #load an image and resize it to 224,224 like vgg face input size\n",
    "            img=img_to_array(img) #convert the image to an array\n",
    "            img=np.expand_dims(img,axis=0) #add the 4th dimension as a tensor to inject through the vgg face network\n",
    "            img=utils.preprocess_input(img, version=preprocess_vgg_version) #preprocess the image\n",
    "            feature_vector=vgg_face_model.predict(img) #extract the features\n",
    "\n",
    "            feature_vectors.append(feature_vector) #append the current feature vector to the gallery\n",
    "            labels.append(str(directory)) #append the current label to the gallery\n",
    "    \n",
    "    feature_vectors=np.squeeze(np.array(feature_vectors), axis=1)\n",
    "    labels=np.expand_dims(np.array(labels),axis=1)\n",
    "    \n",
    "\n",
    "    gallery=np.concatenate((feature_vectors, labels), axis=1)\n",
    "\n",
    "\n",
    "    csv_filename= model_type+'_'+datetime.now().strftime('%Y_%m_%d-at-%H_%M_%S.csv')\n",
    "    pd.DataFrame(gallery).to_csv(output_path+'/'+csv_filename)\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('Feature Extraction Work is Finished Using the {} Pretrained Mode'.format(model_type.upper()))\n",
    "    print('--------------------------------')\n",
    "    print('Number of extracted features: {}'.format(np.shape(feature_vectors)[0]))\n",
    "    print('Number of classes: {}'.format(np.shape(directories)[0]))\n",
    "    print('Saved to : {}/{}'.format(output_path,csv_filename))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "The Feature Extraction Work Has Started Using The VGG16 Prerained Mode\n",
      "----------------------------------------------------\n",
      "WARNING:tensorflow:From C:\\Users\\nkben\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Extracting features from Bale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:05<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Denzel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 41.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Gosling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Gyllenhaal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Hetfield\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 38.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Jackie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:01<00:00, 33.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Madds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 39.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Pitt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 35.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Statham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 44.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Feature Extraction Work is Finished Using the VGG16 Pretrained Mode\n",
      "--------------------------------\n",
      "Number of extracted features: 441\n",
      "Number of classes: 9\n",
      "Saved to : d:\\Projects\\Deep Learning\\Internship - EXIA A4 -2021_2022/gallery/vgg16_2021_12_22-at-22_35_14.csv\n",
      "----------------------------------------------------\n",
      "The Feature Extraction Work Has Started Using The RESNET50 Prerained Mode\n",
      "----------------------------------------------------\n",
      "Extracting features from Bale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:02<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Denzel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 36.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Gosling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Gyllenhaal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Hetfield\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Jackie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:01<00:00, 28.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Madds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 36.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Pitt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Statham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 37.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Feature Extraction Work is Finished Using the RESNET50 Pretrained Mode\n",
      "--------------------------------\n",
      "Number of extracted features: 441\n",
      "Number of classes: 9\n",
      "Saved to : d:\\Projects\\Deep Learning\\Internship - EXIA A4 -2021_2022/gallery/resnet50_2021_12_22-at-22_35_35.csv\n"
     ]
    }
   ],
   "source": [
    "for MODEL in MODELS:\n",
    "    extract_n_save(MODEL,DATASET_PATH,GALLERY_PATH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2665097fc4ce516606e956c6204c3983ee82c67aa1a9762c0115b5dd20c4b36b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
