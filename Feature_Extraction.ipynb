{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](logos/cesi_exia.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### **Internship Project: Access Control Prototype using Facial Biometry**\n",
    "#### **Internship Period: 08/12/2021 - 03/02/2022**\n",
    "\n",
    "\n",
    "|Authors|Country|City|School|Campus|Position|Created|Updated|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|MD. HEMCH|Algeria|Oran|CESI ALGERIE|Oran|Student|21/12/2021|21/12/2021|\n",
    "|NK. BENAMARA|Algeria|Oran|CESI ALGERIE|Oran|Internship Supervisor|21/12/2021|21/12/2021|\n",
    "\n",
    "---\n",
    "\n",
    "|Packages|Version|\n",
    "|---|---|\n",
    "|Numpy|1.19.5|\n",
    "|Opencv|4.5.4.60|\n",
    "|Tensorflow-GPU|1.15|\n",
    "|Keras|2.2.4|\n",
    "|VGG-Face Keras|0.6|\n",
    "|h5py|2.10.0|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH=os.getcwd()\n",
    "GALLERY_PATH=MAIN_PATH+'/gallery'\n",
    "DATASET_PATH=MAIN_PATH+'/dataset_cropped'\n",
    "MODELS=['vgg16', 'resnet50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vggface_model(model_type):\n",
    "    '''\n",
    "    this function load a pretrained VGG Face model (VGG16 or RESNET50)\n",
    "    '''\n",
    "    return VGGFace(model=model_type, include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "def extract_n_save(model_type, dataset_path, output_path, output_type):\n",
    "    ''''\n",
    "    this function extracts and saves features in a npy file\n",
    "    '''\n",
    "    print('----------------------------------------------------')\n",
    "    print('The Feature Extraction Work Has Started Using The {} Prerained Mode'.format(model_type.upper()))\n",
    "    print('----------------------------------------------------')\n",
    "    if model_type=='vgg16':\n",
    "        preprocess_vgg_version=1\n",
    "    elif model_type=='resnet50':\n",
    "        preprocess_vgg_version=2\n",
    "\n",
    "    supported_output_extensions=['npy', 'csv']\n",
    "    vgg_face_model=load_vggface_model(model_type)\n",
    "    feature_vectors=[]\n",
    "    labels=[]\n",
    "    directories=os.listdir(dataset_path)\n",
    "    \n",
    "    for directory in directories:\n",
    "        print('Extracting features from {}'.format(str(directory)))\n",
    "        os.chdir(dataset_path+'/'+directory)\n",
    "        images=glob('*')\n",
    "        for image in tqdm(images):\n",
    "            img=load_img(image,target_size=(224,224)) #load an image and resize it to 224,224 like vgg face input size\n",
    "            img=img_to_array(img) #convert the image to an array\n",
    "            img=np.expand_dims(img,axis=0) #add the 4th dimension as a tensor to inject through the vgg face network\n",
    "            img=utils.preprocess_input(img, version=preprocess_vgg_version) #preprocess the image\n",
    "            feature_vector=vgg_face_model.predict(img) #extract the features\n",
    "\n",
    "            feature_vectors.append(feature_vector) #append the current feature vector to the gallery\n",
    "            labels.append(str(directory)) #append the current label to the gallery\n",
    "    \n",
    "    feature_vectors=np.squeeze(np.array(feature_vectors), axis=1)\n",
    "    labels=np.expand_dims(np.array(labels),axis=1)\n",
    "\n",
    "\n",
    "    if output_type not in supported_output_extensions:\n",
    "        print('The output extenstion is incorrect. The available extensions are : {}'.format(supported_output_extensions))\n",
    "    else:\n",
    "        data_filename= model_type+'_x-train_'+datetime.now().strftime('%Y_%m_%d-at-%H_%M_%S.'+ output_type)\n",
    "        labels_filename= model_type+'_y-train_'+datetime.now().strftime('%Y_%m_%d-at-%H_%M_%S.'+ output_type)\n",
    "\n",
    "        print('--------------------------------')\n",
    "        print('Feature Extraction Work is Finished Using the {} Pretrained Mode'.format(model_type.upper()))\n",
    "        print('--------------------------------')\n",
    "        print('Number of extracted features: {}'.format(np.shape(feature_vectors)[0]))\n",
    "        print('Number of classes: {}'.format(np.shape(directories)[0]))\n",
    "\n",
    "        if output_type=='npy':\n",
    "    \n",
    "            np.save(output_path+'/'+data_filename,feature_vectors)\n",
    "            np.save(output_path+'/'+labels_filename,labels)\n",
    "\n",
    "            print('Saved to : {}/{}'.format(output_path,data_filename))\n",
    "            print('Saved to : {}/{}'.format(output_path,labels_filename))\n",
    "    \n",
    "        elif output_type=='csv':\n",
    "            csv_data=np.concatenate((feature_vectors, labels), axis=1)\n",
    "            pd.DataFrame(csv_data).to_csv(output_path+'/'+data_filename)\n",
    "            \n",
    "            print('Saved to : {}/{}'.format(output_path,data_filename))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "The Feature Extraction Work Has Started Using The VGG16 Prerained Mode\n",
      "----------------------------------------------------\n",
      "npy\n",
      "False\n",
      "Extracting features from Bale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:02<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Denzel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Gosling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 35.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Gyllenhaal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 35.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Hetfield\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Jackie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:01<00:00, 37.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Madds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 36.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Pitt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from Statham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 39.37it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b3537c0f1781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mextract_n_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGALLERY_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-e4c3c6d053ca>\u001b[0m in \u001b[0;36mextract_n_save\u001b[1;34m(model_type, dataset_path, output_path, output_type)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'npy'\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'csv'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The output extenstion is incorrect. It should be npy or csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "for MODEL in MODELS:\n",
    "    extract_n_save(MODEL,DATASET_PATH,GALLERY_PATH,'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2665097fc4ce516606e956c6204c3983ee82c67aa1a9762c0115b5dd20c4b36b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
